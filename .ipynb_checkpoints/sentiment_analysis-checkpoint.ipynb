{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Discourse and Emotions Around the Invasion of Ukraine - Companion code\n",
    "## – A Text Analytics Approach \n",
    "### Gabriel Lindelöf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyarrow import feather\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "tqdm.pandas() # used for apply with progress bar \n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def to_datetime(date):\n",
    "    '''Convert to datetime object.'''\n",
    "    date = datetime.fromisoformat(date[:-1])\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['author_id', 'text', 'text_clean', 'public_metrics.retweet_count', 'public_metrics.like_count', 'author.public_metrics.followers_count']\n",
    "df = feather.read_feather('data/ukraine_two_weeks_clean_shuffled_v2.feather', columns = columns) # import DF with relevant columns\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valence and intensity classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#nltk.download('vader_lexicon')\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(s):\n",
    "    '''Let VADER analyze sentiment of texts.\n",
    "    \n",
    "    Parameter: s (pd.Series): A series containing the column text_clean.\n",
    "    \n",
    "    Returns: a pd.Series object containing the positive, negative, neutral score as well as compound score. \n",
    "    '''\n",
    "    result = analyzer.polarity_scores(s.text_clean) \n",
    "    pos = result['pos']\n",
    "    neg = result['neg']\n",
    "    neu = result['neu']\n",
    "    comp = result['compound']\n",
    "    \n",
    "    return pd.Series([pos, neg, neu, comp], index=['pos', 'neg', 'neu', 'comp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['pos', 'neg', 'neu', 'comp']] = df.progress_apply(get_sentiment, axis = 1) # Get sentiment of  texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_senti_categories(df):\n",
    "    '''Adds categorical variables for sentiment. Also calcuates intensity.'''\n",
    "    \n",
    "    # look at compund score to decide category.\n",
    "    df['is_neg'] = df.comp.apply(lambda x: True if x < 0 else False) \n",
    "    df['is_pos'] = df.comp.apply(lambda x: True if x > 0 else False)\n",
    "    df['is_neu'] = df.comp.apply(lambda x: True if x == 0 else False)\n",
    "    \n",
    "    # also add single summarizing variable for other use cases.\n",
    "    df['polarity'] = df.comp.apply(lambda x: 'negative' if x < 0 else ('positive' if x > 0 else 'neutral'))\n",
    "    \n",
    "    # calculate intensity\n",
    "    df['intensity'] = df.comp.apply(abs)\n",
    "\n",
    "    \n",
    "    print('Negative: ', df.is_neg.sum()/len(df))\n",
    "    print('Positive: ', df.is_pos.sum()/len(df))\n",
    "    print('Neutral: ', df.is_neu.sum()/len(df))\n",
    "    print('Mean sentiment: ', df.comp.sum()/len(df))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.progress_apply(get_senti_categories, axis = 1) # get categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment to retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['author_id', 'text', 'text_clean', 'public_metrics.retweet_count', 'public_metrics.like_count', 'author.public_metrics.followers_count']\n",
    "df = feather.read_feather('data/ukraine_two_weeks_clean_shuffled_v2.feather', columns = columns)\n",
    "\n",
    "# Add previously calculated sentiment data to DF\n",
    "x = feather.read_feather('data/vader_sentiment_shuffled_v2.feather') \n",
    "df = df.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'public_metrics.retweet_count':'retweets', 'public_metrics.like_count':'likes'}) # easier names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(df['intensity'], q = 4).value_counts() # get quantiles of intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the relationship between intensity and number of retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "df['bins'] = pd.qcut(df['intensity'], q = 4) # Divide into quantiles for more easily read plot.\n",
    "\n",
    "# Group by quantile and add standard error.\n",
    "ax = df[['bins','retweets']].groupby('bins').mean().plot(linestyle='--', marker='o', color='b', yerr = df[['bins','retweets']].groupby('bins').sem()) \n",
    "\n",
    "\n",
    "font = {'size' : 15}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(10, 8)\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "ax.set_ylabel('Retweets (mean)')\n",
    "ax.set_xlabel('Intensity (quantile)')\n",
    "ax.get_legend().remove()\n",
    "ax.set_xticklabels(labels = ['', 'Q1', '', 'Q2', '', 'Q3', '', 'Q4', ''])\n",
    "plt.show()\n",
    "fig.savefig('plots/intensity_retweets.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression intensity & retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "X = df.intensity#[(df.retweets > 0)]\n",
    "y = df.retweets\n",
    "\n",
    "\n",
    "slope, intercept, r, p, std_err = stats.linregress(X, y) # Run linear regression. \n",
    "print(\"slope: \", slope)\n",
    "print(\"intercept: \", intercept)\n",
    "print(\"r: \", r)\n",
    "print(\"r2: \", '{:f}'.format(r**2))\n",
    "print(\"p: \", p)\n",
    "print(\"std_err: \", std_err)\n",
    "\n",
    "\n",
    "# Verify results using other package.\n",
    "import statsmodels.api as sm\n",
    "X = df.intensity\n",
    "y = df.likes\n",
    "\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment in topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic.backend._utils import select_backend\n",
    "from bertopic import BERTopic\n",
    "import pickle\n",
    "\n",
    "model_name = 'model_1mil_v13_14t'\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "topic_model = BERTopic.load('models/{}'.format(model_name), embedding_model=sentence_model) # Load topic model.\n",
    "topics = pickle.load(open('models/{}_all.pickle'.format(model_name),'rb')) # Load topic labels. \n",
    "\n",
    "# add topic info to DF\n",
    "df['topic'] = topics \n",
    "df['topic_name'] = df.topic.apply(lambda x: topic_model.get_topic(x)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom topic names to be used in figures. \n",
    "topic_names = {\n",
    "-1:'The invasion',\n",
    "0:'NATO',\n",
    "1:'Foreign\\nstudents',\n",
    "2:'Refugees &\\nracism',\n",
    "3:'Nazism',\n",
    "4:'China',\n",
    "5:'Cryptocurrency',\n",
    "6:'Energy',\n",
    "7:'Airplanes',\n",
    "8:'Other\\nconflicts',\n",
    "9:'Attacked\\ncities',\n",
    "10:'Nuclear\\nplants',\n",
    "11:'Biolabs',\n",
    "12:'COVID-19',\n",
    "13:'National\\nsymbols',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare polarity between topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_count = df[['topic', 'is_pos', 'is_neg', 'is_neu']].groupby('topic').sum() # Get number of tweets with each polarity by topic\n",
    "mean_count['total'] = mean_count.sum(axis=1) # Add total column\n",
    "\n",
    "# Convert to fractions of each polarity by topic. \n",
    "mean_count['is_pos_perc'] = mean_count.is_pos / mean_count.total \n",
    "mean_count['is_neg_perc'] = mean_count.is_neg / mean_count.total\n",
    "mean_count['is_neu'] = mean_count.is_neu / mean_count.total\n",
    "\n",
    "mean_count = mean_count.reset_index()\n",
    "mean_count['topic_name'] = mean_count.topic.apply(lambda x: topic_names[x]) # Add custom topic names. \n",
    "mean_count = mean_count.set_index('topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "@ticker.FuncFormatter\n",
    "def major_formatter(x, pos):\n",
    "    x = round(x, 1)\n",
    "    label = str(-x) if x < 0 else str(x)\n",
    "    return label\n",
    "\n",
    "palette = sns.color_palette(\"deep\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "\n",
    "font = {'size'   : 19}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "\n",
    "positive_perc = mean_count.is_pos_perc.tolist()\n",
    "negative_perc = [x * -1 for x in mean_count.is_neg_perc.tolist()]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(mean_count.topic_name, positive_perc, width=0.9, color=palette[2])\n",
    "ax.bar(mean_count.topic_name, negative_perc, width=0.9, color=palette[3])\n",
    "\n",
    "#ax.set_title('Percentage of positive versus negative tweets in for each topic', fontsize = 30, pad = 20)\n",
    "ax.set_xlabel('Topic', fontsize = 30, labelpad=20)\n",
    "ax.set_ylabel('Fraction of tweets',fontsize = 30, labelpad=20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(30, 10)\n",
    "fig.tight_layout()\n",
    "ax.grid(True, axis = 'y')\n",
    "plt.ylim([-0.8, 0.8])\n",
    "ax.yaxis.set_major_formatter(major_formatter)\n",
    "\n",
    "\n",
    "fig.show()\n",
    "plt.savefig('plots/polarity_topics', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total % positive: ', df.is_pos.sum()/len(df))\n",
    "print('Total % negative: ', df.is_neg.sum()/len(df))\n",
    "print('Total % neutral: ', df.is_neu.sum()/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_count.sort_values(by = 'is_pos_perc', ascending = False).round(3) # Compare most positive, changed to neg or neutral for other comparisons. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare most/least polarized topics \n",
    "mean_count['diff'] = mean_count.is_neg_perc - mean_count.is_pos_perc \n",
    "mean_count.sort_values(by = 'diff', ascending = False).round(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare intensity between topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_intensity = df[['topic', 'intensity']].groupby('topic').mean() # Mean intensity by topic\n",
    "mean_intensity = mean_intensity.reset_index()\n",
    "mean_intensity['topic_name'] = mean_intensity.topic.apply(lambda x: topic_names[x]) # Get topic names\n",
    "mean_intensity = mean_intensity.set_index('topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "font = {'size'   : 19}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(mean_intensity.topic_name, mean_intensity.intensity, width=0.9, color=palette[3])\n",
    "\n",
    "\n",
    "ax.set_xlabel('Topic', fontsize = 30, labelpad=20)\n",
    "ax.set_ylabel('Avergage Intensity',fontsize = 30, labelpad=20)\n",
    "\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(30, 10)\n",
    "fig.tight_layout()\n",
    "ax.grid(True, axis = 'y')\n",
    "\n",
    "ax.yaxis.set_major_formatter(major_formatter)\n",
    "\n",
    "\n",
    "fig.show()\n",
    "plt.savefig('plots/intensity_topics.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create table of intensity and number of documents in topic. \n",
    "intensity_freq = df[['topic', 'intensity']].groupby('topic').mean().join(df.groupby('topic').size().rename('freq'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test difference using linear regression.\n",
    "import statsmodels.api as sm\n",
    "X = intensity_freq.intensity\n",
    "y = intensity_freq.freq\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize tweets (used in estimate_primary_emotions.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer(preserve_case=False, strip_handles=True) # Initiate tokenizer made for tweets. \n",
    "df['tok'] = df.text_clean.progress_apply(lambda x: tt.tokenize(x)) # Tokenize tweets, to be able to count individual words\n",
    "df.to_feather('data/ukraine_two_weeks_clean_shuffled_v2_tok.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stimuli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagion of emotions - machine learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = feather.read_feather('data/response_10000_roberta.feather') # Load estimated emotions of tweets calculated in estimate_emotions_roberta.py\n",
    "stimuli = feather.read_feather('data/roberta_emotions_stimuli_0_1000.feather') # The same for the stimuli tweets\n",
    "response['created_at'] = response['created_at'].apply(to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify tweet as the emotion with dominant score. \n",
    "stimuli['emotion'] = stimuli[['anger', 'joy', 'optimism','sadness']].idxmax(axis = 1)\n",
    "response['emotion'] = response[['anger', 'joy', 'optimism','sadness']].idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge into stimuli and response into a single DF for calculations. \n",
    "stimuli = pd.merge(stimuli, response[['author_id', 'created_at']], left_on=\"followed_by\", how=\"left\", right_on = 'author_id', suffixes = ['', '_resp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long time before response was timuli created?\n",
    "stimuli['time_diff'] = stimuli.created_at_resp - stimuli.created_at \n",
    "stimuli['diff_mins'] = stimuli.time_diff.apply(lambda x: round(x.total_seconds() / 60, 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(stimuli))\n",
    "stimuli = stimuli[stimuli.diff_mins < 60]# Remove tweets made more than an hour before response. \n",
    "print(len(stimuli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add count of how many stimuli tweets each response has\n",
    "stimuli = pd.merge(stimuli, stimuli.groupby('followed_by').size().rename(\"followed_by_stim_count\"), on=\"followed_by\", how=\"left\", suffixes = ['', '_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli = stimuli[stimuli.followed_by_stim_count >= 20] # Remove those with fewer than 20 stimuli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_emotions(n):\n",
    "    '''Samples a random set of n tweets from all stimuli tweets. The fraction of tweets with each emotion in the random sample is then returned'''\n",
    "    c = stimuli.emotion.sample(n, replace = True).value_counts(normalize=True) # Get fraction of each emotions in a random sample of n\n",
    "    \n",
    "    # set to 0 in case dictonary does not contain an emotion. \n",
    "    anger = 0\n",
    "    joy = 0\n",
    "    optimism = 0\n",
    "    sadness = 0\n",
    "    total = c.sum()\n",
    "    \n",
    "    # Get the fraction of each emotion that was randomly sampled. \n",
    "    if 'anger' in c.keys():\n",
    "        anger = c['anger']\n",
    "    if 'joy' in c.keys():\n",
    "        joy = c['joy']\n",
    "    if 'optimism' in c.keys():\n",
    "        optimism = c['optimism']\n",
    "    if 'sadness' in c.keys():\n",
    "        sadness = c['sadness']\n",
    "    return pd.Series([anger,joy,optimism,sadness,total], index = ['anger', 'joy', 'optimism','sadness','total'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples n random tweets for each user based on the number of tweets they had seen, and gets the fraction of each emotion in that sample. \n",
    "# Used to create a baseline simulating that users had seen tweets with random emotions, nullifying contagion. \n",
    "x = pd.DataFrame(stimuli.followed_by.value_counts()).followed_by.apply(sample_emotions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = feather.read_feather('data/sample_emotions_1000.feather') # Load previous sampling to have consistent results of analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline mean: \")\n",
    "baseline = x[['anger', 'joy', 'optimism','sadness']].mean() # Get the mean of all response tweets. \n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline tandard error: \")\n",
    "err = x[['anger', 'joy', 'optimism','sadness']].sem() # Get standard error for baseline\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF containing stimuli and response tweets\n",
    "stimuli = pd.merge(stimuli, response[['author_id', 'emotion']], left_on=\"followed_by\", how=\"left\", right_on = 'author_id', suffixes = ['', '_resp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF containing the response tweets and fractions of tweets in stimuli with each emotion\n",
    "resp_stimuli = pd.DataFrame(stimuli[['followed_by', 'emotion', 'emotion_resp']].groupby('followed_by').emotion.value_counts(normalize = True)).rename(columns = {'emotion':'em'}).reset_index().pivot(index = 'followed_by'\n",
    ",columns='emotion', values='em').fillna(0)\n",
    "\n",
    "# Add info about response tweets emotion to DF.\n",
    "resp_stimuli = pd.merge(resp_stimuli, response[['author_id', 'emotion']], left_on=\"followed_by\", how=\"left\", right_on = 'author_id', suffixes = ['', '_resp']).rename(columns = {'emotion':'emotion_resp'})\n",
    "\n",
    "# Get mean stimuli for each response emotion\n",
    "outcome_mean = resp_stimuli.groupby('emotion_resp').mean().drop('author_id', axis = 1)\n",
    "outcome_error = resp_stimuli.groupby('emotion_resp').sem().drop('author_id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF with standard error for all groups\n",
    "outcome_error = outcome_error.transpose()\n",
    "outcome_error.index = ['Anger', 'Joy', 'Optimism', 'Sadness']\n",
    "\n",
    "error = pd.DataFrame(err, columns = ['Baseline'])\n",
    "error.index.name = 'response_emotion_error'\n",
    "\n",
    "error = error.transpose()\n",
    "error = error.append(outcome_error)\n",
    "error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF with baseline proportions.\n",
    "props = pd.DataFrame(baseline, columns = ['Baseline'])\n",
    "props.index.name = 'response_emotion'\n",
    "props = props.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames with the actual proportions for each emotion. \n",
    "anger = outcome_mean.loc['anger'].to_frame().transpose()\n",
    "anger.index = ['Anger']\n",
    "anger.index.name = 'response_polarity'\n",
    "\n",
    "joy = outcome_mean.loc['joy'].to_frame().transpose()\n",
    "joy.index = ['Joy']\n",
    "joy.index.name = 'response_polarity'\n",
    "\n",
    "optimism = outcome_mean.loc['anger'].to_frame().transpose()\n",
    "optimism.index = ['Optimism']\n",
    "optimism.index.name = 'response_polarity'\n",
    "\n",
    "sadness = outcome_mean.loc['sadness'].to_frame().transpose()\n",
    "sadness.index = ['Sadness']\n",
    "sadness.index.name = 'response_polarity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all proportions to one DF for visualizations. \n",
    "props = props.append(anger).append(joy).append(optimism).append(sadness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to percent.\n",
    "props = props*100 \n",
    "error = error*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "@ticker.FuncFormatter\n",
    "def major_formatter(x, pos):\n",
    "    x = round(x, 1)\n",
    "    label = str(-x) if x < 0 else str(x)\n",
    "    return label\n",
    "\n",
    "palette = sns.color_palette(\"deep\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "width = 0.5 # bar width      \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12, 8)\n",
    "\n",
    "# Add bars for each emotion, starting at the height of the previous bar. \n",
    "ax.bar(props.index, props.anger, width, label = 'Anger', color = palette[3], yerr = error.anger, error_kw=dict(elinewidth=15))\n",
    "ax.bar(props.index, props.sadness, width, label = 'Sadness', bottom = props.anger, color = palette[0], yerr = error.sadness, error_kw=dict(elinewidth=15))\n",
    "ax.bar(props.index, props.optimism, width, label = 'Optimism', bottom = props.anger + props.sadness, color = palette[1], yerr = error.optimism, error_kw=dict(elinewidth=15))\n",
    "ax.bar(props.index, props.joy, width, label = 'Joy', bottom = props.anger + props.sadness + props.optimism, color = palette[2])\n",
    "\n",
    "# Create labels with standard error for each group and stimuli emotion\n",
    "anglab = ['{}\\n±\\n{}'.format(round(props.anger[i], 2), round(error.anger[i], 2)) for i in range(len(props))]\n",
    "ax.bar_label(ax.containers[1], labels = anglab, label_type='center')\n",
    "\n",
    "sadlab = ['{}\\n±\\n{}'.format(round(props.sadness[i], 2), round(error.sadness[i], 2)) for i in range(len(props))]\n",
    "ax.bar_label(ax.containers[3], labels = sadlab, label_type='center')\n",
    "\n",
    "optlab = ['{}\\n±\\n{}'.format(round(props.optimism[i], 2), round(error.optimism[i], 2)) for i in range(len(props))]\n",
    "ax.bar_label(ax.containers[5], labels = optlab, label_type='center')\n",
    "\n",
    "joylab = ['{}\\n±\\n{}'.format(round(props.joy[i], 2), round(error.joy[i], 2)) for i in range(len(props))]\n",
    "ax.bar_label(ax.containers[6], labels = joylab, label_type='center')\n",
    "\n",
    "\n",
    "\n",
    "plt.ylim((0, 100)) \n",
    "font = {'size' : 13}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "ax.set_ylabel('Percent tweets')\n",
    "ax.set_ylabel('Response emotion')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "lgd = ax.legend(handles[::-1], labels[::-1],title = 'Stimuli emotion %', bbox_to_anchor=(1.01, 1), frameon=False)\n",
    "\n",
    "\n",
    "fig.savefig('plots/emotion_contagion.png', dpi=300, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pingouin import mwu\n",
    "\n",
    "# Create DF with the stimuli tweets proportions for each response tweet as well as baseline. \n",
    "resp_stimuli = pd.DataFrame(stimuli[['followed_by', 'emotion', 'emotion_resp']].groupby('followed_by').emotion.value_counts(normalize = True)).rename(columns = {'emotion':'em'}).reset_index().pivot(index = 'followed_by'\n",
    ",columns='emotion', values='em').fillna(0)\n",
    "resp_stimuli = pd.merge(resp_stimuli, response[['author_id', 'emotion']], left_on=\"followed_by\", how=\"left\", right_on = 'author_id', suffixes = ['', '_resp']).rename(columns = {'emotion':'emotion_resp'})\n",
    "bl = x[['anger', 'joy', 'optimism', 'sadness']]\n",
    "bl['emotion_resp'] = 'baseline'\n",
    "resp_stimuli = resp_stimuli.append(bl)\n",
    "\n",
    "\n",
    "sig_results = 0\n",
    "for group in ['anger', 'joy', 'optimism', 'sadness']:\n",
    "    for em in ['anger', 'joy', 'optimism', 'sadness']:\n",
    "        a = resp_stimuli.groupby('emotion_resp').get_group(group)[em] # Get distribution for group to be compared\n",
    "        b = resp_stimuli.groupby('emotion_resp').get_group('baseline')[em] # Get corresponding baseline\n",
    "        \n",
    "        mwu_result = mwu(a, b, alternative='two-sided') # Test significance\n",
    "        if mwu_result['p-val'][0] < 0.05:\n",
    "            print(\"\\n\\n*The {} group has a significantly different distribution of {} than baseline.\".format(group, em))\n",
    "            print(mwu_result)\n",
    "            sig_results += 1\n",
    "        else: \n",
    "            print(\"\\n\\nThe {} group does NOT have a significatly different distribution of {} than baseline.\".format(group, em))\n",
    "            print(mwu_result)\n",
    "print(\"Significant results: \", sig_results)\n",
    "        \n",
    "            \n",
    "        \n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagion of emotions - polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli[['pos', 'neg', 'neu', 'comp']] = stimuli.progress_apply(get_sentiment, axis = 1) # Get sentiment for all stimuli tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response[['pos', 'neg', 'neu', 'comp']] = response.progress_apply(get_sentiment, axis = 1) # Get sentiment for all response tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also get categorical variables\n",
    "response = get_senti_categories(response) \n",
    "stimuli = get_senti_categories(stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_polarity(n):\n",
    "    '''Samples a random set of n tweets from all stimuli tweets. The fraction of tweets with each polarity in the random sample is then returned'''\n",
    "    c = stimuli.polarity.sample(n, replace = True).value_counts(normalize=True)\n",
    "    \n",
    "    # Set to zero in case a stimuli does not contain a polarity.\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    neutral = 0\n",
    "    \n",
    "    # Get fractions for each polarity\n",
    "    if 'positive' in c.keys():\n",
    "        positive = c['positive']\n",
    "    if 'negative' in c.keys():\n",
    "        negative = c['negative']\n",
    "    if 'neutral' in c.keys():\n",
    "        neutral = c['neutral']\n",
    "\n",
    "        \n",
    "    return pd.Series([positive,negative,neutral], index = ['positive', 'negative', 'neutral']) # Return as pd.Series. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = pd.DataFrame(stimuli.followed_by.value_counts()).followed_by.apply(sample_polarity) # Run sampling to get baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = feather.read_feather('data/sample_polarity_1000.feather') # Load previously taken sample for consistent results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline mean: \")\n",
    "baseline = x[['positive', 'negative', 'neutral']].mean() # Get baseline, mean of all tweets. \n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline tandard error: \")\n",
    "err = x[['positive', 'negative', 'neutral']].sem() # Get standard error for baseline\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF containing stimuli and response tweets\n",
    "stimuli = pd.merge(stimuli, response[['author_id', 'polarity']], left_on=\"followed_by\", how=\"left\", right_on = 'author_id', suffixes = ['', '_resp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF containing the response tweets and fractions of tweets in stimuli with each polarity. \n",
    "resp_stimuli = pd.DataFrame(stimuli[['followed_by', 'polarity', 'polarity_resp']].groupby('followed_by').polarity.value_counts(normalize = True)).rename(columns = {'polarity':'pol'}).reset_index().pivot(index = 'followed_by'\n",
    ",columns='polarity', values='pol').fillna(0)\n",
    "\n",
    "# Add info about response tweets own polarity to DF.\n",
    "resp_stimuli = pd.merge(resp_stimuli, response[['author_id', 'polarity']], left_on=\"followed_by\", how=\"left\", right_on = 'author_id', suffixes = ['', '_resp']).rename(columns = {'polarity':'polarity_resp'})\n",
    "\n",
    "# Get mean stimuli for each response polarity\n",
    "outcome_mean = resp_stimuli.groupby('polarity_resp').mean().drop('author_id', axis = 1)\n",
    "outcome_error = resp_stimuli.groupby('polarity_resp').sem().drop('author_id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF containing standard error for baseline\n",
    "outcome_error = outcome_error.transpose()\n",
    "outcome_error.index = ['Negative', 'Neutral', 'Positive']\n",
    "error = pd.DataFrame(err, columns = ['Baseline'])\n",
    "error.index.name = 'response_polarity_error'\n",
    "error = error.transpose()\n",
    "error = error.append(outcome_error)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF containing baseline proportions\n",
    "props = pd.DataFrame(baseline, columns = ['Baseline'])\n",
    "props.index.name = 'response_polarity'\n",
    "props = props.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DF for each response group containing the proportions of stimuli.\n",
    "neg = outcome_mean.loc['negative'].to_frame().transpose()\n",
    "neg.index = ['Negative']\n",
    "neg.index.name = 'response_polarity'\n",
    "\n",
    "neu = outcome_mean.loc['neutral'].to_frame().transpose()\n",
    "neu.index = ['Neutral']\n",
    "neu.index.name = 'response_polarity'\n",
    "\n",
    "pos = outcome_mean.loc['positive'].to_frame().transpose()\n",
    "pos.index = ['Positive']\n",
    "pos.index.name = 'response_polarity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into a single DF for visualization. \n",
    "props = props.append(neg).append(neu).append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to percent. \n",
    "props = props*100\n",
    "error = error*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette(\"deep\")\n",
    "@ticker.FuncFormatter\n",
    "def major_formatter(x, pos):\n",
    "    x = round(x, 1)\n",
    "    label = str(-x) if x < 0 else str(x)\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "width = 0.5 # bar width     \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 10)\n",
    "\n",
    "# Add bars for each group, start on top of previous groups bar. \n",
    "ax.bar(props.index, props.positive, width, bottom = (props.neutral + props.negative), label = 'Positive', color = palette[2])#, yerr = pos_error\n",
    "ax.bar(props.index, props.neutral, width, bottom = props.negative, label = 'Neutral', color = palette[7], yerr = error.neutral, error_kw=dict(elinewidth=15))\n",
    "ax.bar(props.index, props.negative, width, label = 'Negative', color = palette[3], yerr = error.negative, error_kw=dict(elinewidth=15))\n",
    "\n",
    "\n",
    "ax.grid(True, axis = 'y', which = 'both')\n",
    "ax.yaxis.set_major_formatter(major_formatter)\n",
    "\n",
    "\n",
    "# Add labels indicating standard error.\n",
    "poslab = ['{}\\n±\\n{}'.format(round(props.positive[i], 2), round(error.positive[i], 2))  for i in range(len(props))]\n",
    "ax.bar_label(ax.containers[0], labels = poslab, label_type='center')\n",
    "\n",
    "neulab = ['{}\\n±\\n{}'.format(round(props.neutral[i], 2), round(error.neutral[i], 2))  for i in range(len(props))]\n",
    "ax.bar_label(ax.containers[2], labels = neulab, label_type='center')\n",
    "\n",
    "neglab = ['{}\\n±\\n{}'.format(round(props.negative[i], 2), round(error.negative[i], 2))  for i in range(len(props))]\n",
    "ax.bar_label(ax.containers[4], labels = neglab, label_type='center')\n",
    "\n",
    "\n",
    "plt.ylim((0, 100)) \n",
    "\n",
    "\n",
    "font = {'size' : 15}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "ax.set_ylabel('Percent tweets')\n",
    "ax.set_xlabel('Response polarity')\n",
    "lgd = ax.legend(title = 'Stimuli polarity %', loc = 'upper right', bbox_to_anchor=(1.2, 1), frameon=False)\n",
    "fig.savefig('plots/polarity_contagion.png', dpi=300, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF containg each response tweets emotion and the stimuli distribution. \n",
    "resp_stimuli = pd.DataFrame(stimuli[['followed_by', 'polarity', 'polarity_resp']].groupby('followed_by').polarity.value_counts(normalize = True)).rename(columns = {'polarity':'pol'}).reset_index().pivot(index = 'followed_by'\n",
    ",columns='polarity', values='pol').fillna(0)\n",
    "resp_stimuli = pd.merge(resp_stimuli, response[['author_id', 'polarity']], left_on=\"followed_by\", how=\"left\", right_on = 'author_id', suffixes = ['', '_resp']).rename(columns = {'polarity':'polarity_resp'})\n",
    "bl = x[['positive', 'negative', 'neutral']]\n",
    "bl['polarity_resp'] = 'baseline'\n",
    "resp_stimuli = resp_stimuli.append(bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distributions visually. \n",
    "resp_stimuli.groupby('polarity_resp').get_group('negative').negative.plot.hist() \n",
    "resp_stimuli.groupby('polarity_resp').get_group('positive').negative.plot.hist()\n",
    "resp_stimuli.groupby('polarity_resp').get_group('baseline').negative.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.normaltest(resp_stimuli.groupby('polarity_resp').get_group('baseline').negative) # Test if normal distribution, was done for all groups and polarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test significance to baseline for each group and polarity.\n",
    "sig_results = 0\n",
    "for group in ['positive', 'negative', 'neutral']:\n",
    "    \n",
    "    for em in ['positive', 'negative', 'neutral']:\n",
    "        a = resp_stimuli.groupby('polarity_resp').get_group(group)[em] # To be tested. \n",
    "        b = resp_stimuli.groupby('polarity_resp').get_group('baseline')[em] # Baseline for corresponding emotion. \n",
    "        \n",
    "        mwu_result = mwu(a, b, alternative='less')\n",
    "        if mwu_result['p-val'][0] < 0.05:\n",
    "            print(\"\\n\\n*The {} group has a significantly different distribution of {} than baseline.\".format(group, em))\n",
    "            print(mwu_result)\n",
    "            sig_results += 1\n",
    "        else: \n",
    "            print(\"\\n\\nThe {} group does NOT have a significatly different distribution of {} than baseline.\".format(group, em))\n",
    "            print(mwu_result)\n",
    "print(\"Significant results: \", sig_results)\n",
    "        \n",
    "            \n",
    "        \n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare using barplots, not used in final paper.\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 10)\n",
    "ax = sns.boxplot(data = resp_stimuli, x = 'polarity_resp', y = 'negative', notch = True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 10)\n",
    "ax = sns.boxplot(data = resp_stimuli, x = 'polarity_resp', y = 'positive', notch = True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 10)\n",
    "ax = sns.boxplot(data = resp_stimuli, x = 'polarity_resp', y = 'neutral', notch = True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_stimuli = pd.DataFrame(stimuli[['followed_by', 'emotion', 'emotion_resp']].groupby('followed_by').emotion.value_counts(normalize = True)).rename(columns = {'emotion':'em'}).reset_index().pivot(index = 'followed_by'\n",
    ",columns='emotion', values='em').fillna(0)\n",
    "\n",
    "resp_stimuli = pd.merge(resp_stimuli, response[['author_id', 'emotion']], left_on=\"followed_by\", how=\"left\", right_on = 'author_id', suffixes = ['', '_resp']).rename(columns = {'emotion':'emotion_resp'})\n",
    "\n",
    "bl = x[['anger', 'joy', 'optimism', 'sadness']]\n",
    "bl['emotion_resp'] = 'baseline'\n",
    "resp_stimuli = resp_stimuli.append(bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 10)\n",
    "ax = sns.boxplot(data = resp_stimuli, x = 'emotion_resp', y = 'anger', notch = True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 10)\n",
    "ax = sns.boxplot(data = resp_stimuli, x = 'emotion_resp', y = 'sadness', notch = True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 10)\n",
    "ax = sns.boxplot(data = resp_stimuli, x = 'emotion_resp', y = 'optimism', notch = True)\n",
    "fig.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 10)\n",
    "ax = sns.boxplot(data = resp_stimuli, x = 'emotion_resp', y = 'joy', notch = True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotions in topics - lexical approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = feather.read_feather('data/ukraine_two_weeks_clean_shuffled_v2_8emotions.feather') # Emotions labeled using estimate_primary_emotions.py\n",
    "df = df.join(pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_words_topic = df[['topic', 'trust', 'fear', 'sadness', 'anger', 'surprise', 'disgust', 'joy', 'anticipation']].groupby('topic').mean() # Get mean count of words per topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to fractions, then multiply by 100 to get percentages. \n",
    "mean_words_topic[['trust', 'fear', 'sadness', 'anger', 'surprise', 'disgust', 'joy', 'anticipation']] = mean_words_topic[[\n",
    "                'trust', 'fear', 'sadness', 'anger', 'surprise', 'disgust', 'joy', 'anticipation']].apply(lambda x: (x/x.sum()) *100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add topic names. \n",
    "mean_words_topic.reset_index(inplace = True)\n",
    "mean_words_topic['topic_name'] = mean_words_topic.topic.apply(lambda x: topic_names[x]) \n",
    "mean_words_topic.set_index('topic', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline, mean of all topics for each emotion\n",
    "em_bl = pd.DataFrame(mean_words_topic.mean()).transpose()\n",
    "em_bl['topic_name'] = 'baseline'\n",
    "em_bl.index = [-2]\n",
    "mean_words_topic = mean_words_topic.append(em_bl).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette(\"deep\")\n",
    "\n",
    " \n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(30, 15)\n",
    "\n",
    "\n",
    "\n",
    "width = 0.75 # Bar width \n",
    "bottom_total = 0 # Bottom bar location\n",
    "\n",
    "\n",
    "# Plot bars on top of each other with set color and label.\n",
    "em_col = {'trust':1, 'fear':4, 'sadness':0, 'anger':3, 'surprise':9, 'disgust':5, 'joy':2, 'anticipation':8}\n",
    "for em in ['fear', 'trust', 'anger', 'anticipation', 'sadness', 'joy', 'surprise', 'disgust']:#[::-1]:\n",
    "    ax.bar(mean_words_topic.topic_name, mean_words_topic[em], width, label = em, color = palette[em_col[em]], bottom = bottom_total)\n",
    "    bottom_total +=  mean_words_topic[em]\n",
    "    \n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "lgd = ax.legend(handles[::-1], labels[::-1],title = 'Emotion', bbox_to_anchor=(1.01, 1), frameon=False, fontsize = 25)\n",
    "lgd.get_title().set_fontsize(25)\n",
    "\n",
    "#ylabels = ['{:.0f}'.format(x) + 'k' for x in ax.get_yticks()/1000]\n",
    "\n",
    "baseline_hatches = []\n",
    "pos = 0\n",
    "for i in range(8): # Prepares hatch locations for baseline. \n",
    "    baseline_hatches.append(pos)\n",
    "    pos += len(mean_words_topic)\n",
    "    \n",
    "bars = ax.patches\n",
    "for bar in baseline_hatches: # Add hatches. \n",
    "    bars[bar].set_hatch('/')\n",
    "\n",
    "# Add difference from baseline as labels. \n",
    "for i, em in enumerate(['fear', 'trust', 'anger', 'anticipation', 'sadness', 'joy', 'surprise', 'disgust']):\n",
    "    em_diffs = mean_words_topic[em] - mean_words_topic[em][-2] \n",
    "    lab = [('+\\n{}'.format(round(em_diffs[i], 1))) if em_diffs[i] >= 0 else '━\\n{}'.format(str(round(em_diffs[i], 1))[1:]) for i in range(-2, len(em_diffs)-2)]\n",
    "    ax.bar_label(ax.containers[i], labels = lab, label_type='center', fontsize = 16, weight = 'bold')\n",
    "\n",
    "ax.set_ylabel('Average %', fontsize = 30, labelpad=20)\n",
    "ax.set_xlabel('Topics', fontsize = 30, labelpad=20)\n",
    "sns.set(font_scale = 1.5)\n",
    "plt.xlim([-1,len(mean_words_topic.topic_name)])\n",
    "plt.ylim(0,100)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "ax.texts[119].set_fontsize(10)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('plots/primary_emotions_topics.png', dpi=300, bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotions in topics - machine learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sample = feather.read_feather('data/sample_topic_emotions_5000_each_14t.feather') # Get tweets labeled in estimate_emotions_roberta.py\n",
    "len(topic_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean percentage of each emotion in topics\n",
    "mean_em = topic_sample.groupby('topic').mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_em.reset_index(inplace = True)\n",
    "mean_em['topic_name'] = mean_em.topic.apply(lambda x: topic_names[x]) # Add topic names.\n",
    "mean_em.set_index('topic', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline representing mean emotion of all topics. \n",
    "em_bl = pd.DataFrame(mean_em.mean()).transpose()\n",
    "em_bl['topic_name'] = 'baseline'\n",
    "em_bl.index = [-2]\n",
    "mean_em = mean_em.append(em_bl).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette(\"deep\")\n",
    "\n",
    " \n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(30, 15)\n",
    "\n",
    "width = 0.75    \n",
    "bottom_total = 0\n",
    "\n",
    "# Place bars on top of eachother colored and labeled with emotions. \n",
    "em_col = {'anger':3, 'sadness':0, 'optimism':8, 'joy':2}\n",
    "for em in ['anger', 'sadness', 'optimism', 'joy']:\n",
    "    ax.bar(mean_em.topic_name, mean_em[em], width, label = em, color = palette[em_col[em]], bottom = bottom_total)\n",
    "    bottom_total +=  mean_em[em]\n",
    "    \n",
    "\n",
    "    \n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "lgd = ax.legend(handles[::-1], labels[::-1],title = 'Emotion', bbox_to_anchor=(1.01, 1), frameon=False, fontsize = 25)\n",
    "lgd.get_title().set_fontsize(25)\n",
    "\n",
    "baseline_hatches = []\n",
    "pos = 0\n",
    "for i in range(4): # Prepare hatch locations for baseline bar. \n",
    "    baseline_hatches.append(pos)\n",
    "    pos += len(mean_em)\n",
    "    \n",
    "bars = ax.patches\n",
    "for bar in baseline_hatches: # Add hatches. \n",
    "    bars[bar].set_hatch('/')\n",
    "    \n",
    "for i, em in enumerate(['anger', 'sadness', 'optimism', 'joy']):\n",
    "    em_diffs = mean_em[em] - mean_em[em][-2] \n",
    "    lab = [('+ {}'.format(str(round(em_diffs[i], 1)))) if em_diffs[i] >= 0 else '━ {}'.format(str(round(em_diffs[i], 1))[1:]) for i in range(-2, len(em_diffs)-2)]\n",
    "    ax.bar_label(ax.containers[i], labels = lab, label_type='center', fontsize = 15, weight = 'bold')\n",
    "\n",
    "ax.set_ylabel('Average %', fontsize = 30, labelpad=20)\n",
    "ax.set_xlabel('Topics', fontsize = 30, labelpad=20)\n",
    "sns.set(font_scale = 1.5)\n",
    "plt.xlim([-1,len(mean_em.topic_name)])\n",
    "plt.ylim(0,100)\n",
    "plt.show()\n",
    "fig.savefig('emotions_topics_roberta.png', dpi=300, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contagion of intensity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the response valence for each stimuli tweet. \n",
    "stimuli = pd.merge(stimuli, response[['author_id', 'comp']], left_on=\"followed_by\", how=\"left\", right_on = 'author_id', suffixes = ['', '_resp'])\n",
    "stimuli = pd.merge(stimuli, response[['author_id', 'polarity']], left_on=\"followed_by\", how=\"left\", right_on = 'author_id', suffixes = ['', '_resp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli['intensity_resp'] = stimuli.comp_resp.apply(abs) # Convert valence to intensity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot intensity stimuli on intensity resp.\n",
    "plt.scatter(stimuli.intensity, stimuli.intensity_resp, color='red', s = 0.1, alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# Group stimuli intensity into quantile bins. \n",
    "stimuli['bins'] = pd.cut(stimuli.intensity, bins = 4, duplicates = 'raise')\n",
    "\n",
    "# Plot average intensity response for each quantile group. \n",
    "ax = stimuli[['bins','intensity_resp']].groupby('bins').mean().plot(linestyle='--', marker='o', color='b', yerr = stimuli[['bins','intensity_resp']].groupby('bins').sem())\n",
    "\n",
    "\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(10, 8)d\n",
    "\n",
    "ax.set_ylabel('Response intensity')\n",
    "ax.set_xlabel('Stimuli intensity (quantile)')\n",
    "ax.get_legend().remove()\n",
    "ax.set_xticklabels(labels = ['', 'Q1', '', 'Q2', '', 'Q3', '', 'Q4', ''])\n",
    "\n",
    "font = {'size' : 11}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.show()\n",
    "fig.savefig('plots/stim_resp_intensity.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Linear regression between intensity stimuli and intensity response. \n",
    "X = stimuli.intensity\n",
    "y = stimuli.intensity_resp\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables indicating positivity and negativity separately. \n",
    "stimuli['comp_pos'] = stimuli.comp.apply(lambda x: abs(x) if x > 0 else 0)\n",
    "stimuli['comp_neg'] = stimuli.comp.apply(lambda x: abs(x) if x < 0 else 0)\n",
    "\n",
    "stimuli = pd.merge(stimuli, response[['author_id', 'anger', 'sadness', 'joy', 'optimism']], left_on=\"followed_by\", how=\"left\", right_on = 'author_id', suffixes = ['', '_resp'])\n",
    "mean_stim = stimuli[['followed_by', 'pos', 'neg', 'neu', 'intensity', 'intensity_resp', 'comp', 'comp_resp', 'comp_pos', 'comp_neg', 'anger', 'sadness', 'joy', 'optimism', 'anger_resp', 'sadness_resp', 'joy_resp', 'optimism_resp']].groupby('followed_by').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Test what valence response positivity and negativity predicts. \n",
    "X = mean_stim[['comp_pos', 'comp_neg']]\n",
    "y = mean_stim.comp_resp\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
